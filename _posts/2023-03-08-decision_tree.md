---
layout: post
title: "机器学习 - 决策树"
subtitle: "Machine Learning"
date: 2023-03-08 14:40:00 +0800
categories: [AI]
---

# 机器学习 - 决策树(Decision Tree)

## 基本流程

- 决策树是一类常见的机器学习方法，是基于树结构来进行决策的，这恰是人类在面临决策问题时一种很自然的处理机制

- 决策过程的最终结论对应了我们所希望的判定结果，决策过程中提出的每个判定问题都是对某个属性的“测试”

- 一般一棵决策树包含一个根节点、若干个内部节点和若干个叶节点；叶节点对应于决策结果，其他每个节点则对应于一个属性测试

- 决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的“分而治之”策略

```PseudoCode
输入: 训练集D={(x1, y1), (x2, y2), ..., (xm, ym)}
    属性集A={a1, a2, ..., ad}
过程: 函数TreeGenerate(D, A)

生成节点node;

if D中样本全属于同一类别C then
    将node标记为C类叶节点; return
end if

if A=ø OR D中样本在A上取值相同 then
    将node标记为叶节点，其类别标记为D中样本数最多的类; return
end if

从A中选择最优划分属性a*;

for a*的每一个值a*v do
    为node生成一个分支; 令Dv表示D中在a*上取值为a*v的样本子集;
    if Dv为空 then
        将分支节点标记为叶节点，其类别标记为D中样本最多的类; return
    else
        以TreeGenerate(Dv, A \ {a*})为分支节点
    end if
end for

输出: 以node为根节点的一棵决策树
```

在决策树的基本算法中，有三种情形会导致递归返回:

1. 当前节点包含的样本全属于同一类别，无需划分
2. 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分
3. 当前节点包含的样本集合为空，不能划分

> 情形2是利用当前结点的后验分布，而情形3则是把父结点的样本分布作为当前结点的先验分布

***

## 划分选择

- 由以上的伪代码中可以看出，决策树学习的关键是“从A中选择最优划分属性a*”，即如何选择最优划分属性

> 一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”越来越高

### 信息增益

- "信息熵(information entropy)"是度量样本集合纯度最常用的一种指标

假定当前样本集合D中的第k类样本所占的比例为$p_k$，则D的信息熵定义为:
>>>>>>> ce66408f0240ae591d2f02b8bcd3e29b36f77645
$$
    Ent(D) = - \sum
$$
